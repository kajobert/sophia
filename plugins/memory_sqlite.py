from pathlib import Path
from plugins.base_plugin import BasePlugin, PluginType
from core.context import SharedContext
from core.operation_metadata import OperationMetadata
from sqlalchemy import create_engine, Table, Column, Integer, String, Float, Boolean, MetaData, insert, select, and_
from typing import List, Dict, Optional
import json
import logging

logger = logging.getLogger(__name__)


class SQLiteMemory(BasePlugin):
    """A memory plugin that stores conversation history in a SQLite database."""

    @property
    def name(self) -> str:
        return "memory_sqlite"

    @property
    def plugin_type(self) -> PluginType:
        return PluginType.MEMORY

    @property
    def version(self) -> str:
        return "1.0.0"

    def setup(self, config: dict) -> None:
        """Initializes the database connection and creates the table if it doesn't exist."""
        db_path_str = config.get("db_path", "data/memory/sophia_memory.db")

        # Ensure the directory for the database exists
        db_path = Path(db_path_str)
        db_path.parent.mkdir(parents=True, exist_ok=True)

        self.engine = create_engine(f"sqlite:///{db_path_str}")
        self.metadata = MetaData()
        
        # Conversation history table
        self.history_table = Table(
            "conversation_history",
            self.metadata,
            Column("id", Integer, primary_key=True),
            Column("session_id", String),
            Column("role", String),
            Column("content", String),
            Column("operation_metadata", String),  # JSON-serialized OperationMetadata
        )
        
        # Operation tracking table (for self-improvement and offline dreaming)
        self.operation_tracking_table = Table(
            "operation_tracking",
            self.metadata,
            Column("id", Integer, primary_key=True),
            Column("operation_id", String, unique=True, nullable=False),
            Column("session_id", String),
            Column("timestamp", String, nullable=False),
            Column("model_used", String, nullable=False),
            Column("model_type", String, nullable=False),
            Column("operation_type", String, nullable=False),
            Column("offline_mode", Boolean, nullable=False, default=False),
            Column("success", Boolean, nullable=False, default=True),
            Column("quality_score", Float),
            Column("evaluated_at", String),
            Column("evaluation_model", String),
            Column("prompt_tokens", Integer),
            Column("completion_tokens", Integer),
            Column("total_tokens", Integer),
            Column("latency_ms", Float),
            Column("error_message", String),
            Column("raw_metadata", String),  # Full JSON for extensibility
        )
        
        # Hypotheses table (Phase 3.1 - Self-Learning Loop)
        # Stores improvement hypotheses generated by reflection plugin
        self.hypotheses_table = Table(
            "hypotheses",
            self.metadata,
            Column("id", Integer, primary_key=True),
            Column("hypothesis_text", String, nullable=False),
            Column("created_at", String, nullable=False),
            Column("source_failure_id", Integer),  # FK to operation_tracking
            Column("status", String, nullable=False, default="pending"),  # pending|testing|approved|rejected
            Column("test_results", String),  # JSON with benchmark data
            Column("priority", Integer, default=50),  # 1-100
            Column("category", String),  # code_fix|prompt_optimization|model_change|config_tuning
            Column("root_cause", String),  # Root cause analysis
            Column("proposed_fix", String),  # Detailed fix description
            Column("estimated_improvement", String),  # e.g., "15%"
            Column("tested_at", String),  # Timestamp of testing
            Column("approved_at", String),  # Timestamp of approval
            Column("deployed_at", String),  # Timestamp of deployment
        )
        
        self.metadata.create_all(self.engine)
        logger.info(f"SQLite memory initialized: {db_path_str}")

    async def execute(self, context: SharedContext) -> SharedContext:
        """Saves the current user input and LLM response to the database."""
        user_input = context.user_input
        llm_response = context.payload.get("llm_response")

        if not user_input or not llm_response:
            return context

        with self.engine.connect() as conn:
            conn.execute(
                insert(self.history_table).values(
                    session_id=context.session_id, role="user", content=user_input
                )
            )
            conn.execute(
                insert(self.history_table).values(
                    session_id=context.session_id, role="assistant", content=llm_response
                )
            )
            conn.commit()
            context.logger.info(
                "Saved interaction to short-term memory.",
                extra={"plugin_name": self.name},
            )

        return context

    def get_history(self, session_id: str, limit: int = 10) -> List[Dict[str, str]]:
        """Retrieves the most recent history for a session."""
        with self.engine.connect() as conn:
            stmt = (
                select(self.history_table.c.role, self.history_table.c.content)
                .where(self.history_table.c.session_id == session_id)
                .order_by(self.history_table.c.id.desc())
                .limit(limit)
            )
            results = conn.execute(stmt).fetchall()
            return [{"role": row[0], "content": row[1]} for row in reversed(results)]
    
    # ===== OPERATION TRACKING METHODS (NEW) =====
    
    def save_operation(self, metadata: OperationMetadata) -> None:
        """
        Save operation metadata to tracking table.
        
        Args:
            metadata: OperationMetadata instance to store
        """
        with self.engine.connect() as conn:
            conn.execute(
                insert(self.operation_tracking_table).values(
                    operation_id=metadata.operation_id,
                    session_id=metadata.session_id,
                    timestamp=metadata.timestamp,
                    model_used=metadata.model_used,
                    model_type=metadata.model_type,
                    operation_type=metadata.operation_type,
                    offline_mode=metadata.offline_mode,
                    success=metadata.success,
                    quality_score=metadata.quality_score,
                    evaluated_at=metadata.evaluated_at,
                    evaluation_model=metadata.evaluation_model,
                    prompt_tokens=metadata.prompt_tokens,
                    completion_tokens=metadata.completion_tokens,
                    total_tokens=metadata.total_tokens,
                    latency_ms=metadata.latency_ms,
                    error_message=metadata.error_message,
                    raw_metadata=metadata.to_json(),
                )
            )
            conn.commit()
            logger.debug(f"Saved operation {metadata.operation_id} to tracking table")
    
    def get_unevaluated_offline_operations(self, limit: Optional[int] = None) -> List[OperationMetadata]:
        """
        Get all offline operations that haven't been evaluated yet.
        
        Args:
            limit: Maximum number of operations to return (None = all)
        
        Returns:
            List of OperationMetadata instances
        """
        with self.engine.connect() as conn:
            stmt = (
                select(self.operation_tracking_table)
                .where(
                    and_(
                        self.operation_tracking_table.c.offline_mode == True,
                        self.operation_tracking_table.c.quality_score == None
                    )
                )
                .order_by(self.operation_tracking_table.c.timestamp.desc())
            )
            
            if limit:
                stmt = stmt.limit(limit)
            
            results = conn.execute(stmt).fetchall()
            
            # Convert to OperationMetadata instances
            operations = []
            for row in results:
                metadata = OperationMetadata.from_json(row[-1])  # raw_metadata is last column
                operations.append(metadata)
            
            logger.info(f"Found {len(operations)} unevaluated offline operations")
            return operations
    
    def update_operation_quality(
        self,
        operation_id: str,
        quality_score: float,
        evaluation_model: str,
        evaluated_at: str
    ) -> None:
        """
        Update operation with quality evaluation results.
        
        Args:
            operation_id: Operation identifier
            quality_score: Quality score (0.0-1.0)
            evaluation_model: Model used for evaluation
            evaluated_at: Timestamp of evaluation
        """
        from sqlalchemy import update
        
        with self.engine.connect() as conn:
            stmt = (
                update(self.operation_tracking_table)
                .where(self.operation_tracking_table.c.operation_id == operation_id)
                .values(
                    quality_score=quality_score,
                    evaluation_model=evaluation_model,
                    evaluated_at=evaluated_at
                )
            )
            conn.execute(stmt)
            conn.commit()
            logger.debug(f"Updated operation {operation_id} with quality score {quality_score:.2f}")
    
    def get_operation_statistics(self, days: int = 7) -> Dict:
        """
        Get statistics about operations over the last N days.
        
        Args:
            days: Number of days to analyze
        
        Returns:
            Dictionary with statistics
        """
        from datetime import datetime, timedelta
        
        cutoff_date = (datetime.now() - timedelta(days=days)).isoformat()
        
        with self.engine.connect() as conn:
            # Total operations
            stmt = select(self.operation_tracking_table).where(
                self.operation_tracking_table.c.timestamp >= cutoff_date
            )
            all_ops = conn.execute(stmt).fetchall()
            
            total_count = len(all_ops)
            offline_count = sum(1 for op in all_ops if op[7])  # offline_mode column
            online_count = total_count - offline_count
            
            # Quality scores
            offline_scores = [op[9] for op in all_ops if op[7] and op[9] is not None]  # quality_score
            online_scores = [op[9] for op in all_ops if not op[7] and op[9] is not None]
            
            stats = {
                "days_analyzed": days,
                "total_operations": total_count,
                "offline_operations": offline_count,
                "online_operations": online_count,
                "offline_percentage": (offline_count / total_count * 100) if total_count > 0 else 0,
                "offline_avg_quality": sum(offline_scores) / len(offline_scores) if offline_scores else None,
                "online_avg_quality": sum(online_scores) / len(online_scores) if online_scores else None,
                "quality_gap": None
            }
            
            if stats["offline_avg_quality"] and stats["online_avg_quality"]:
                stats["quality_gap"] = stats["online_avg_quality"] - stats["offline_avg_quality"]
            
            return stats

    # === HYPOTHESIS MANAGEMENT (Phase 3.1) ===
    
    def create_hypothesis(
        self,
        hypothesis_text: str,
        category: str,
        priority: int = 50,
        source_failure_id: Optional[int] = None,
        root_cause: Optional[str] = None,
        proposed_fix: Optional[str] = None,
        estimated_improvement: Optional[str] = None
    ) -> int:
        """
        Create a new improvement hypothesis.
        
        Args:
            hypothesis_text: Description of the hypothesis
            category: code_fix|prompt_optimization|model_change|config_tuning
            priority: 1-100 (higher = more important)
            source_failure_id: ID of the operation_tracking entry that triggered this
            root_cause: Root cause analysis
            proposed_fix: Detailed fix description
            estimated_improvement: Expected improvement (e.g., "15%")
            
        Returns:
            int: ID of created hypothesis
        """
        from datetime import datetime
        
        with self.engine.connect() as conn:
            result = conn.execute(
                insert(self.hypotheses_table).values(
                    hypothesis_text=hypothesis_text,
                    created_at=datetime.now().isoformat(),
                    source_failure_id=source_failure_id,
                    status="pending",
                    priority=priority,
                    category=category,
                    root_cause=root_cause,
                    proposed_fix=proposed_fix,
                    estimated_improvement=estimated_improvement
                )
            )
            conn.commit()
            
            hypothesis_id = result.lastrowid
            logger.info(f"[Memory] Created hypothesis #{hypothesis_id}: {category} (priority: {priority})")
            
            return hypothesis_id
    
    def get_pending_hypotheses(self, limit: int = 10) -> List[Dict]:
        """
        Get pending hypotheses ordered by priority (highest first).
        
        Args:
            limit: Maximum number of hypotheses to return
            
        Returns:
            List of hypothesis dictionaries
        """
        with self.engine.connect() as conn:
            stmt = select(self.hypotheses_table).where(
                self.hypotheses_table.c.status == "pending"
            ).order_by(
                self.hypotheses_table.c.priority.desc()
            ).limit(limit)
            
            rows = conn.execute(stmt).fetchall()
            
            hypotheses = []
            for row in rows:
                hypotheses.append({
                    "id": row[0],
                    "hypothesis_text": row[1],
                    "created_at": row[2],
                    "source_failure_id": row[3],
                    "status": row[4],
                    "test_results": json.loads(row[5]) if row[5] else None,
                    "priority": row[6],
                    "category": row[7],
                    "root_cause": row[8],
                    "proposed_fix": row[9],
                    "estimated_improvement": row[10]
                })
            
            return hypotheses
    
    def update_hypothesis_status(
        self,
        hypothesis_id: int,
        status: str,
        test_results: Optional[Dict] = None
    ) -> None:
        """
        Update hypothesis status and optionally test results.
        
        Args:
            hypothesis_id: ID of hypothesis to update
            status: pending|testing|approved|rejected
            test_results: Dictionary with benchmark data
        """
        from sqlalchemy import update
        from datetime import datetime
        
        update_values = {"status": status}
        
        if test_results:
            update_values["test_results"] = json.dumps(test_results)
        
        # Set timestamps based on status
        if status == "testing":
            update_values["tested_at"] = datetime.now().isoformat()
        elif status == "approved":
            update_values["approved_at"] = datetime.now().isoformat()
        elif status == "deployed":
            update_values["deployed_at"] = datetime.now().isoformat()
        
        with self.engine.connect() as conn:
            conn.execute(
                update(self.hypotheses_table)
                .where(self.hypotheses_table.c.id == hypothesis_id)
                .values(**update_values)
            )
            conn.commit()
            
            logger.info(f"[Memory] Updated hypothesis #{hypothesis_id} status: {status}")
    
    def get_hypothesis_by_id(self, hypothesis_id: int) -> Optional[Dict]:
        """
        Get hypothesis by ID.
        
        Args:
            hypothesis_id: ID of hypothesis
            
        Returns:
            Hypothesis dictionary or None if not found
        """
        with self.engine.connect() as conn:
            stmt = select(self.hypotheses_table).where(
                self.hypotheses_table.c.id == hypothesis_id
            )
            
            row = conn.execute(stmt).fetchone()
            
            if not row:
                return None
            
            return {
                "id": row[0],
                "hypothesis_text": row[1],
                "created_at": row[2],
                "source_failure_id": row[3],
                "status": row[4],
                "test_results": json.loads(row[5]) if row[5] else None,
                "priority": row[6],
                "category": row[7],
                "root_cause": row[8],
                "proposed_fix": row[9],
                "estimated_improvement": row[10],
                "tested_at": row[11],
                "approved_at": row[12],
                "deployed_at": row[13]
            }
