# Prompt Optimization - AktuÃ¡lnÃ­ Stav a Action Plan

**Date:** 2025-11-06  
**KritiÄnost:** ğŸ”´ **VYSOKÃ** - KlÃ­ÄovÃ¡ pro AMI self-tuning  
**Status:** âš ï¸ ÄŒÃSTEÄŒNÄš IMPLEMENTOVÃNO

---

## ğŸ” CO MÃME (SouÄasnÃ½ Stav)

### âœ… 1. Cognitive Reflection Plugin (648 lines) - COMPLETE

**File:** `plugins/cognitive_reflection.py`

**Co dÄ›lÃ¡:**
- âœ… Analyzuje failure patterns z operation_tracking
- âœ… VytvÃ¡Å™Ã­ hypotheses pomocÃ­ Expert LLM (4-tier escalation)
- âœ… Identifikuje `fix_type`: **code_fix | prompt_optimization | config_tuning | model_change**
- âœ… UklÃ¡dÃ¡ hypotÃ©zy do databÃ¡ze

**Prompt Analysis Template (lines 412-441):**
```python
prompt = f"""Jsi expert na debugging AI systÃ©mÅ¯. Analyzuj tyto selhÃ¡nÃ­:

OPERACE: {operation_type}
ÃšSPÄšÅ NOST: {success_rate}%
PÅ˜ÃKLADY CHYB: {error_samples}

ÃšKOL:
1. Identifikuj ROOT CAUSE (ne symptom!)
2. Navrhni KONKRÃ‰TNÃ FIX (zmÄ›na kÃ³du, prompt, config, nebo model)
3. Odhadni IMPACT (high/medium/low)

VraÅ¥ JSON:
{{
  "root_cause": "...",
  "hypothesis": "...",
  "proposed_fix": "...",
  "fix_type": "code_fix|prompt_optimization|config_tuning|model_change",  â­
  "priority": 1-100,
  "estimated_improvement": "15%"
}}
"""
```

**âœ… UmÃ­ identifikovat, kdy je potÅ™eba prompt optimization!**

---

### âœ… 2. Self-Tuning Plugin (1193 lines) - COMPLETE

**File:** `plugins/cognitive_self_tuning.py`

**Co dÄ›lÃ¡:**
- âœ… ZpracovÃ¡vÃ¡ hypotÃ©zy z Reflection pluginu
- âœ… **Podporuje 4 typy fixÅ¯:**
  - `code` - Ãšprava Python kÃ³du âœ…
  - **`prompt` - Optimalizace promptÅ¯** âœ… â­
  - `config` - ZmÄ›na YAML konfigurace âœ…
  - `model` - ZmÄ›na LLM modelu âœ…

**Prompt Fix Implementation (lines 343-348):**
```python
elif fix_type == "prompt":
    # Prompt fix: Create optimized prompt file
    sandbox_file = sandbox_dir / "config/prompts" / target_file
    sandbox_file.parent.mkdir(parents=True, exist_ok=True)
    sandbox_file.write_text(proposed_fix)
    
    self.logger.info(f"âœï¸  Created optimized prompt: {sandbox_file}")
```

**Prompt Benchmarking (lines 558-597):**
```python
async def _benchmark_prompt(self, workspace_root, sandbox_dir, target_file):
    """
    Benchmark prompt optimization.
    
    Compare old vs new prompt:
    - Read baseline prompt
    - Read new optimized prompt
    - Measure length (shorter = better for 8B models)
    - Estimate improvement based on length reduction
    
    For MVP: Conservative estimate (15% improvement if shorter/clearer)
    """
    # Read both prompts
    baseline_prompt = (workspace_root / "config/prompts" / target_file).read_text()
    new_prompt = (sandbox_dir / "config/prompts" / target_file).read_text()
    
    # Shorter prompt usually better for 8B models
    baseline_len = len(baseline_prompt)
    new_len = len(new_prompt)
    
    improvement = (baseline_len - new_len) / baseline_len if new_len < baseline_len else 0
    
    return {
        "baseline_length": baseline_len,
        "new_length": new_len,
        "improvement": improvement,
        "success": True
    }
```

**âœ… UmÃ­ aplikovat a testovat prompt optimalizace!**

---

### âš ï¸ 3. Prompt Optimizer Plugin (392 lines) - INFRASTRUCTURE ONLY

**File:** `plugins/cognitive_prompt_optimizer.py`

**Co dÄ›lÃ¡:**
- âœ… Event subscription (TASK_COMPLETED) âœ…
- âœ… Prompt version tracking âœ…
- âœ… A/B testing infrastructure âœ…
- âœ… Metrics tracking âœ…

**Co NEDÄšLÃ (TODO komentÃ¡Å™e):**
- âŒ `_gather_training_examples()` â†’ vracÃ­ `[]` (line 282)
- âŒ `_analyze_response_patterns()` â†’ vracÃ­ `{"insights": "placeholder"}` (line 290)
- âŒ `_generate_improved_prompt()` â†’ vracÃ­ `"Improved prompt template placeholder"` (line 300)
- âŒ `_should_optimize()` â†’ vracÃ­ `False` (line 209) **âš ï¸ KRITICKÃ‰!**

**ProÄ nebÄ›Å¾Ã­:**
```python
def _should_optimize(self, task_type: str) -> bool:
    """Determine if prompts should be optimized..."""
    # ... checks ...
    
    # For now, return False to avoid spurious optimizations
    return False  # âš ï¸ HARDCODED FALSE!
```

**âŒ Plugin je "vypnutÃ½" - nikdy nespustÃ­ optimalizaci!**

---

## ğŸ”„ JAK TO FUNGUJE DNES (Workflow)

### SouÄasnÃ½ Autonomous Workflow:

```
1. ERROR occurs (task fails)
   â†“
2. DREAM_COMPLETE event (memory consolidation)
   â†“
3. Cognitive Reflection analyzes failures
   â†“
4. Creates hypothesis with fix_type="prompt_optimization"  âœ…
   â†“
5. Hypothesis stored in database  âœ…
   â†“
6. Self-Tuning Plugin picks up hypothesis  âœ…
   â†“
7. Applies prompt fix in sandbox  âœ…
   â†“
8. Benchmarks prompt (length comparison)  âœ…
   â†“
9. Deploys if improvement > 10%  âœ…
   â†“
10. Creates git commit + PR  âœ…
```

**âœ… WORKFLOW JE KOMPLETNÃ!**

**Ale:**
- âš ï¸ Reflection plugin musÃ­ **sprÃ¡vnÄ› identifikovat** prompt issues
- âš ï¸ `proposed_fix` musÃ­ obsahovat **novÃ½ optimalizovanÃ½ prompt text**

---

## â“ CO CHYBÃ (Gap Analysis)

### ğŸ”´ KRITICKÃ CHYBÄšJÃCÃ KROK:

**Cognitive Reflection vytvÃ¡Å™Ã­ hypotheses, ale:**
- â“ **Odkud vezme "proposed_fix" pro prompt optimization?**
- â“ **Kdo vygeneruje novÃ½ optimalizovanÃ½ prompt?**

**SouÄasnÃ© Å™eÅ¡enÃ­:**
- Reflection plugin volÃ¡ Expert LLM (4-tier escalation) âœ…
- LLM vracÃ­ JSON s `proposed_fix` âœ…
- **ALE:** LLM musÃ­ dostat **sprÃ¡vnÃ½ prompt**, aby vygeneroval **celÃ½ novÃ½ prompt text**!

**ProblÃ©m:**
- Analysis prompt (lines 412-441) Å¾Ã¡dÃ¡ o "KONKRÃ‰TNÃ FIX"
- Ale **nespecifikuje**, Å¾e pro prompt_optimization musÃ­ vrÃ¡tit **plnÃ½ novÃ½ prompt text**
- LLM mÅ¯Å¾e vrÃ¡tit jen "ZkraÅ¥te prompt" mÃ­sto skuteÄnÃ©ho textu!

---

## ğŸ¯ CO POTÅ˜EBUJEME DODÄšLAT

### Priority 1: VylepÅ¡it Reflection Analysis Prompt (30 minut)

**File:** `plugins/cognitive_reflection.py` (lines 412-441)

**ZmÄ›na:**
PÅ™idat speciÃ¡lnÃ­ sekci pro `prompt_optimization`:

```python
def _build_analysis_prompt(self, operation_type, failures, error_samples, success_rate):
    prompt = f"""Jsi expert na debugging AI systÃ©mÅ¯. Analyzuj tyto selhÃ¡nÃ­:

OPERACE: {operation_type}
POÄŒET SELHÃNÃ: {len(failures)} za poslednÃ­ch 7 dnÃ­
ÃšSPÄšÅ NOST: {success_rate}%

PÅ˜ÃKLADY CHYB:
{error_samples}

ÃšKOL:
1. Identifikuj ROOT CAUSE (ne symptom!)
2. Navrhni KONKRÃ‰TNÃ FIX (zmÄ›na kÃ³du, prompt, config, nebo model)
3. Odhadni IMPACT (high/medium/low)

â­ SPECIÃLNÃ INSTRUKCE PRO PROMPT OPTIMIZATION:
Pokud fix_type="prompt_optimization", pak pole "proposed_fix" MUSÃ obsahovat:
- KOMPLETNÃ novÃ½ prompt text (ne jen popis zmÄ›ny!)
- OptimalizovanÃ½ pro local 8B LLM (llama3.1:8b)
- KratÅ¡Ã­, jasnÄ›jÅ¡Ã­, s konkrÃ©tnÃ­mi pÅ™Ã­klady
- ZachovÃ¡vÃ¡ funkÄnost, ale zjednoduÅ¡uje jazyk

VraÅ¥ JSON:
{{
  "root_cause": "...",
  "hypothesis": "...",
  "proposed_fix": "PLNÃ TEXT novÃ©ho promptu (pokud fix_type=prompt_optimization) nebo popis zmÄ›ny (jinak)",
  "fix_type": "code_fix|prompt_optimization|config_tuning|model_change",
  "priority": 1-100,
  "estimated_improvement": "15%"
}}
"""
    return prompt
```

**â±ï¸ ÄŒasovÃ¡ nÃ¡roÄnost:** 30 minut  
**ğŸ”§ SloÅ¾itost:** LOW  
**âœ… Dopad:** CRITICAL - UmoÅ¾nÃ­ plnou prompt optimization!

---

### Priority 2: VylepÅ¡it Prompt Benchmarking (1 hodina)

**File:** `plugins/cognitive_self_tuning.py` (lines 558-597)

**ProblÃ©m:**
- SouÄasnÃ½ benchmark pouze **porovnÃ¡vÃ¡ dÃ©lku**
- To je **pÅ™Ã­liÅ¡ primitivnÃ­** pro skuteÄnÃ© hodnocenÃ­

**Å˜eÅ¡enÃ­:**
PÅ™idat **real-world testing** na sample inputs:

```python
async def _benchmark_prompt(self, workspace_root, sandbox_dir, target_file):
    """
    Enhanced prompt benchmarking with real-world testing.
    
    1. Load old and new prompts
    2. Get sample inputs from operation_tracking (last 10 examples)
    3. Test both prompts with local 8B LLM
    4. Compare:
       - Success rate (valid JSON, correct format)
       - Response quality (length, clarity)
       - Token usage
    5. Return improvement percentage
    """
    baseline_prompt = (workspace_root / "config/prompts" / target_file).read_text()
    new_prompt = (sandbox_dir / "config/prompts" / target_file).read_text()
    
    # Get sample test cases from database
    test_cases = await self._get_sample_inputs(target_file, limit=10)
    
    if not test_cases:
        # Fallback to length comparison
        return self._compare_prompt_lengths(baseline_prompt, new_prompt)
    
    # Run both prompts on test cases
    baseline_results = await self._test_prompt(baseline_prompt, test_cases)
    new_results = await self._test_prompt(new_prompt, test_cases)
    
    # Calculate improvement
    baseline_success = sum(1 for r in baseline_results if r["valid"]) / len(test_cases)
    new_success = sum(1 for r in new_results if r["valid"]) / len(test_cases)
    
    improvement = (new_success - baseline_success) / baseline_success if baseline_success > 0 else 0
    
    return {
        "baseline_success_rate": baseline_success,
        "new_success_rate": new_success,
        "improvement": improvement,
        "test_cases_count": len(test_cases),
        "success": new_success > baseline_success
    }

async def _get_sample_inputs(self, prompt_file: str, limit: int = 10):
    """Query operation_tracking for recent inputs that used this prompt."""
    # TODO: Implement database query
    pass

async def _test_prompt(self, prompt_text: str, test_cases: List[str]):
    """Test prompt with sample inputs using local 8B LLM."""
    # TODO: Call LLM with prompt + each test case
    pass
```

**â±ï¸ ÄŒasovÃ¡ nÃ¡roÄnost:** 1 hodina  
**ğŸ”§ SloÅ¾itost:** MEDIUM  
**âœ… Dopad:** HIGH - PÅ™esnÄ›jÅ¡Ã­ rozhodovÃ¡nÃ­ o nasazenÃ­

---

### Priority 3: Odstranit Prompt Optimizer Plugin? (0 minut)

**File:** `plugins/cognitive_prompt_optimizer.py`

**OtÃ¡zka:** Je tento plugin jeÅ¡tÄ› potÅ™eba?

**AnalÃ½za:**
- âŒ NebÄ›Å¾Ã­ automaticky (`_should_optimize() = False`)
- âŒ TODO placeholders v critical metodÃ¡ch
- âœ… Reflection + Self-Tuning **uÅ¾ prompt optimization dÄ›lajÃ­!**

**DoporuÄenÃ­:**
- **MOÅ½NOST A:** Smazat plugin (redundantnÃ­)
- **MOÅ½NOST B:** PÅ™epracovat na "Prompt Testing Framework" (Phase 4)
- **MOÅ½NOST C:** Ponechat jako fallback/manual trigger (nÃ­zkÃ¡ priorita)

**ğŸ¯ Pro AMI 1.0:** DoporuÄuji **MOÅ½NOST A** (smazat) nebo **MOÅ½NOST C** (ignorovat)

**â±ï¸ ÄŒasovÃ¡ nÃ¡roÄnost:** 0 minut (ignorovat) nebo 10 minut (smazat)  
**ğŸ”§ SloÅ¾itost:** LOW  
**âœ… Dopad:** LOW (jen Ãºklid kÃ³du)

---

## ğŸ“Š IMPLEMENTAÄŒNÃ PLÃN

### âœ… DoporuÄenÃ© kroky pro AMI 1.0:

| # | Ãškol | Soubor | ÄŒas | Priorita | DÅ¯leÅ¾itost |
|---|------|--------|-----|----------|------------|
| 1 | VylepÅ¡it Reflection prompt | `cognitive_reflection.py` | 30 min | ğŸ”´ CRITICAL | â­â­â­â­â­ |
| 2 | VylepÅ¡it benchmark prompt | `cognitive_self_tuning.py` | 1h | ğŸŸ¡ MEDIUM | â­â­â­â­ |
| 3 | Rozhodnout o Prompt Optimizer | `cognitive_prompt_optimizer.py` | 10 min | ğŸŸ¢ LOW | â­ |

**CelkovÃ½ Äas:** ~1.5 hodiny

**Po implementaci Priority 1:**
- âœ… Reflection bude generovat plnÃ© prompt texty
- âœ… Self-Tuning je aplikuje a testuje
- âœ… **KOMPLETNÃ prompt optimization workflow!**

**Po implementaci Priority 2:**
- âœ… PÅ™esnÄ›jÅ¡Ã­ benchmarking
- âœ… LepÅ¡Ã­ rozhodovÃ¡nÃ­ o deployment
- âœ… VyÅ¡Å¡Ã­ kvalita optimalizacÃ­

---

## ğŸ¯ FINÃLNÃ VERDIKT

### âœ… Prompt Optimization JE implementovÃ¡na!

**Ale:**
- âš ï¸ **Priority 1 je KRITICKÃ** pro sprÃ¡vnou funkÄnost
- âš ï¸ **Priority 2 je DOPORUÄŒENÃ** pro kvalitu

**Pro AMI 1.0:**
- âœ… **Priority 1 MUSÃ bÃ½t hotovÃ¡** (30 min)
- ğŸŸ¡ **Priority 2 je nice-to-have** (1h)
- ğŸŸ¢ **Priority 3 je optional cleanup** (10 min)

**CelkovÃ½ scope pro 100% funkÄnÃ­ prompt optimization:**
- **Minimum:** 30 minut (Priority 1)
- **DoporuÄeno:** 1.5 hodiny (Priority 1 + 2)
- **Maximum:** 1.7 hodiny (vÅ¡e vÄetnÄ› cleanup)

---

## ğŸš€ NEXT STEPS

**ChceÅ¡, abych:**

### MoÅ¾nost A: Implementovat Priority 1 (30 min) âœ… DOPORUÄŒUJI
- VylepÅ¡Ã­m Reflection analysis prompt
- Otestuji na sample hypotÃ©ze
- Prompt optimization bude 100% funkÄnÃ­!

### MoÅ¾nost B: Implementovat Priority 1 + 2 (1.5h) â­ BEST
- Priority 1: Reflection prompt
- Priority 2: Real-world benchmarking
- **KompletnÃ­ enterprise-grade prompt optimization!**

### MoÅ¾nost C: Analyzovat souÄasnÃ½ stav blÃ­Å¾
- Najdu existujÃ­cÃ­ prompty v `config/prompts/`
- Otestuji, jestli Reflection uÅ¾ generuje sprÃ¡vnÃ© hypotÃ©zy
- MoÅ¾nÃ¡ to **uÅ¾ funguje** a jen potÅ™ebuje aktivaci!

**Co preferujeÅ¡?** ğŸ˜Š

---

*AnalÃ½za: 2025-11-06 | Verdikt: 30 min od 100% funkÄnÃ­ho prompt optimization!*
