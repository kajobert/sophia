# Sophia's Idea Backlog

This document contains a backlog of ideas, feature requests, and high-level goals for the development of Sophia. It is inspired by the initial thoughts in `roberts-notes.txt` and is maintained in accordance with the project's development guidelines.

---

## 1. UX/UI Enhancements

### 1.1. Improve Terminal Experience
*   **Goal:** Make the terminal output more user-friendly and easier to debug.
*   **Tasks:**
    *   Implement colorized logging to distinguish between different types of messages (e.g., INFO, WARN, ERROR).
    *   Introduce structured, formatted output for displaying plans, tool calls, and results to improve readability.

### 1.2. Kernel State Visualization
*   **Goal:** Provide real-time visibility into the Kernel's current state and activity.
*   **Tasks:**
    *   Design and implement an "information bar" or status line that displays the current phase of the `consciousness_loop` (e.g., `LISTENING`, `PLANNING`, `EXECUTING`).
    *   Ensure this status is visible in both the terminal interface and the Web UI.

---

## 2. LLM and Logic Improvements

### 2.1. Optimize Tool-Calling Logic
*   **Goal:** Increase the reliability and efficiency of tool calls to minimize retries.
*   **Tasks:**
    *   Conduct a thorough prompt engineering review to refine the instructions the LLM receives for generating plans and tool arguments.
    *   Investigate and implement more robust validation and repair mechanisms to catch and correct errors before execution.

### 2.2. Implement an LLM Debug Mode
*   **Goal:** Create a supervised debugging mode for reviewing and approving AI-generated plans.
*   **Tasks:**
    *   Develop a mechanism that pauses the Kernel after the `PLANNING` phase.
    *   Allow a human developer to review, modify, or approve the generated plan before it proceeds to the `EXECUTING` phase.

---

## 3. Knowledge Transfer and Documentation

### 3.1. Integrate Lessons from "Jules"
*   **Goal:** Transfer the operational knowledge and limitations discovered while working with the "Jules" agent to Sophia.
*   **Tasks:**
    *   Analyze the `WORKLOG.md` and commit history to identify recurring challenges, successful patterns, and architectural constraints.
    *   Codify these findings into a new "Learned Lessons" document in the `docs/learned/` directory to guide Sophia's future self-development.

### 3.2. Maintain Detailed Technical Documentation
*   **Goal:** Ensure that all technical documentation is comprehensive and up-to-date to prevent context loss.
*   **Tasks:**
    *   Establish a strict policy where no new feature is considered complete until its corresponding documentation (`Developer Guide`, `Technical Architecture`, etc.) is updated.
    *   Create a "Developer Manual" that provides clear, step-by-step instructions for common development tasks to help both human and AI developers stay on track.

---

## 4. Kernel and Plugin Architecture

### 4.1. Enhance LLM Compatibility
*   **Goal:** Make the system resilient to the diverse and sometimes non-standard implementations of tool-calling across different LLM providers.
*   **Tasks:**
    *   **Dynamic `tool_choice` Handling:** Implement logic in the `LLMTool` or Kernel to conditionally apply the `tool_choice` parameter based on model/provider-specific needs, avoiding errors with models that do not support it.
    *   **Provider-Specific Adapters:** Consider creating a layer of small adapter modules for different LLM providers (e.g., OpenRouter, Azure) to handle their unique API quirks and requirements gracefully.
    *   **Model Capability Cache:** Develop a caching mechanism to store the known capabilities (e.g., tool support, `tool_choice` support) of models after the first interaction. This would prevent repeated failed attempts on models with known limitations.

### 4.2. Implement Advanced Plan Repair
*   **Goal:** Improve the system's ability to recover from malformed plans generated by LLMs.
*   **Tasks:**
    *   **Structural JSON Repair:** Evolve the current JSON repair mechanism into a more advanced "Plan Repair" system. This system would not only fix syntax errors but also attempt to correct structural issues in the plan's logic (e.g., re-nesting a flattened list of tool calls) by re-prompting the LLM with specific instructions for correction.

### 4.3. Multi-Stage Repair with Model Escalation
*   **Goal:** Implement a more sophisticated repair loop that uses different models based on the complexity of the error.
*   **Tasks:**
    *   Refactor the `Validation & Repair Loop` in `core/kernel.py` to support a multi-stage repair process.
    *   **Attempt 1:** Use a fast, cost-effective model (e.g., `claude-3-haiku`) for the initial repair attempt. This allows for data collection on the capabilities of smaller models.
    *   **Attempt 2+:** If the first attempt fails, escalate to a more powerful, high-quality model (e.g., `claude-3.5-sonnet`) for subsequent attempts to maximize the chance of a successful correction.
    *   This tiered approach optimizes for both cost and success rate, while also providing valuable data for prompt and model strategy optimization.
