# Konfigurace pro Sophia V4

# Režim spuštění: "online" (vyžaduje API klíč) nebo "offline" (používá mock LLM)
execution_mode: "online"

# Databáze pro epizodickou paměť a úkoly
database:
  db_host: "localhost"
  db_port: 5434
  db_user: "sophia_user"
  db_password: "sophia_password"
  db_name: "sophia_db"

logging:
  guardian_log: "logs/guardian.log"
  sophia_main_log: "logs/sophia_main.log"

# Konfigurace pro Large Language Models (LLM)
# Podporuje OpenRouter i přímý Gemini API access
llm_models:
  # Výchozí model, který se použije, pokud není specifikován jiný.
  # Pokud existuje GEMINI_API_KEY, použije se Gemini
  default: "gemini"

  # Aliasy pro různé typy úkolů. Orchestrátor vybírá alias,
  # LLM Manager ho překládá na konkrétní model.
  aliases:
    # Gemini models (direct API)
    powerful: "google/gemini-2.5-flash-lite"       # Gemini 2.5 Flash (experimental, nejnovější)
    economical: "google/gemini-2.5-flash-lite"         # Gemini 1.5 Flash (stabilní)
    gemini: "google/gemini-2.5-flash-lite"         # Default Gemini
    
    # OpenRouter models (multi-provider)
    cheap: "qwen/qwen-2.5-72b-instruct"    # Cheapest: $0.07/1M tokens
    balanced: "google/gemma-3-27b-it"      # Balanced: $0.09/1M tokens
    openrouter: "google/gemini-2.5-flash-lite"  # Fallback na OpenRouter
    fallback: "anthropic/claude-3-haiku" # Fallback pro kritické selhání

  # Seznam dostupných modelů s jejich identifikátory
  # Gemini modely (přímý API access)
  models:
    # === Gemini Models (Direct API) ===
    # Gemini 2.5 Flash Experimental (nejnovější, doporučeno)
    "gemini-2.0-flash-exp":
      temperature: 0.7
      max_output_tokens: 8192
      top_p: 0.95
    
    # Gemini 1.5 Flash (stabilní)
    "gemini-1.5-flash":
      temperature: 0.7
      max_output_tokens: 8192
      top_p: 0.95
    
    # Gemini 1.5 Flash Latest (auto-updated)
    "gemini-1.5-flash-latest":
      temperature: 0.7
      max_output_tokens: 8192
      top_p: 0.95
    
    # === OpenRouter Models ===
    # Cheapest options (< $0.10/1M tokens)
    "qwen/qwen-2.5-72b-instruct":
      temperature: 0.7
      max_tokens: 8000
    
    "google/gemma-3-27b-it":
      temperature: 0.7
      max_tokens: 8000
    
    "deepseek/deepseek-v3.2-exp":
      temperature: 0.7
      max_tokens: 8000
    
    # OpenRouter fallback modely
    "google/gemini-2.5-flash-lite": {}
    "anthropic/claude-3-haiku": {}

  # Seznam záložních modelů pro OpenRouter (pokud Gemini není dostupný)
  fallback_models:
    - "anthropic/claude-3-haiku"
    - "google/gemini-2.5-flash-lite"

# Konfigurace pro Orchestrator
orchestrator:
  # Maximální počet iterací (cyklů), než se agent zastaví.
  max_iterations: 100

# Konfigurace pro Intelligent Guardian
guardian:
  cpu_threshold: 90.0
  ram_threshold: 90.0