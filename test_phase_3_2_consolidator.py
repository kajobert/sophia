"""
Test for Phase 3.2: Cognitive Memory Consolidator Plugin

Tests:
  1. Query operations older than 24h
  2. Separate successes from failures
  3. Create document text from operation
  4. Consolidate to ChromaDB (mock)
  5. Cleanup old operations (>7 days)
  6. DREAM_TRIGGER event handler
  7. DREAM_COMPLETE event emission

Expected Results:
  ‚úÖ Queries old operations correctly
  ‚úÖ Filters successes vs failures
  ‚úÖ Creates searchable document text
  ‚úÖ Consolidation logic works
  ‚úÖ Cleanup deletes old entries
  ‚úÖ Event handling functional
"""

import sys
import logging
from datetime import datetime, timedelta
from pathlib import Path

# Add project root to path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(message)s'
)
logger = logging.getLogger(__name__)

# Import required modules
from plugins.cognitive_memory_consolidator import CognitiveMemoryConsolidator
from plugins.memory_sqlite import SQLiteMemory
from core.events import Event, EventType
from core.event_bus import EventBus


def test_phase_3_2_consolidator():
    """
    Test Cognitive Memory Consolidator infrastructure.
    """
    print("üß™ PHASE 3.2 TEST: Cognitive Memory Consolidator Plugin")
    print()
    
    # Initialize plugins
    memory_plugin = SQLiteMemory()
    memory_plugin.setup({"database_path": "data/memory/test_consolidator.db"})
    
    consolidator = CognitiveMemoryConsolidator()
    event_bus = EventBus()
    
    consolidator.setup({
        "all_plugins": {
            "memory_sqlite": memory_plugin,
            "memory_chroma": None  # Mock for now
        },
        "event_bus": event_bus,
        "consolidation_age_hours": 24,
        "retention_days": 7,
        "batch_size": 100
    })
    
    print("‚úÖ Memory Consolidator plugin initialized")
    print()
    
    # Test 1: Create mock operations with different timestamps
    print("Test 1: Create Mock Operations")
    
    operations = []
    
    # Create 10 old operations (> 24h)
    for i in range(10):
        timestamp = (datetime.now() - timedelta(hours=30 + i)).isoformat()
        success = i % 3 != 0  # 7 successes, 3 failures
        
        memory_plugin.save_operation(
            operation_id=f"op_{i}",
            session_id="test_session_1",
            timestamp=timestamp,
            model_used="llama3.1:8b",
            model_type="local",
            operation_type="llm_call",
            offline_mode=True,
            success=success,
            quality_score=0.85 if success else 0.0,
            prompt_tokens=100,
            completion_tokens=50,
            total_tokens=150,
            latency_ms=250.0,
            error_message=None if success else "Mock failure",
            raw_metadata=f"Test operation {i}"
        )
        
        operations.append({
            "id": i + 1,
            "operation_id": f"op_{i}",
            "success": success,
            "timestamp": timestamp
        })
    
    # Create 5 recent operations (< 24h) - should NOT be consolidated
    for i in range(10, 15):
        timestamp = (datetime.now() - timedelta(hours=12)).isoformat()
        
        memory_plugin.save_operation(
            operation_id=f"op_{i}",
            session_id="test_session_2",
            timestamp=timestamp,
            model_used="llama3.1:8b",
            model_type="local",
            operation_type="llm_call",
            offline_mode=True,
            success=True,
            quality_score=0.90,
            prompt_tokens=100,
            completion_tokens=50,
            total_tokens=150,
            latency_ms=200.0,
            error_message=None,
            raw_metadata=f"Recent operation {i}"
        )
    
    print(f"‚úÖ Created 10 old operations (>24h)")
    print(f"   7 successes, 3 failures")
    print(f"‚úÖ Created 5 recent operations (<24h)")
    print()
    
    # Test 2: Query Old Operations
    print("Test 2: Query Old Operations")
    
    import asyncio
    
    old_ops = asyncio.run(consolidator._get_old_operations())
    
    print(f"üìä Found {len(old_ops)} operations older than 24h")
    
    # Should find 10 old operations
    if len(old_ops) == 10:
        print("‚úÖ Query returned correct count")
    else:
        print(f"‚ùå Expected 10, got {len(old_ops)}")
    
    print()
    
    # Test 3: Separate Successes from Failures
    print("Test 3: Separate Successes from Failures")
    
    successes = [op for op in old_ops if op.get("success")]
    failures = [op for op in old_ops if not op.get("success")]
    
    print(f"   ‚úÖ {len(successes)} successful operations")
    print(f"   ‚ùå {len(failures)} failed operations")
    
    if len(successes) == 7 and len(failures) == 3:
        print("‚úÖ Separation logic correct")
    else:
        print(f"‚ùå Expected 7 successes and 3 failures")
    
    print()
    
    # Test 4: Create Document Text
    print("Test 4: Create Document Text")
    
    if successes:
        sample_op = successes[0]
        doc_text = consolidator._create_document_text(sample_op)
        
        print(f"üìù Sample document text:")
        print(f"   {doc_text[:100]}...")
        
        # Check required elements
        if "Operation" in doc_text and "llama3.1:8b" in doc_text and "offline" in doc_text:
            print("‚úÖ Document text contains required elements")
        else:
            print("‚ùå Document text missing elements")
    
    print()
    
    # Test 5: Consolidate to ChromaDB (Mock)
    print("Test 5: Consolidate to ChromaDB (Mock)")
    
    # Since we don't have real ChromaDB, just verify logic
    if consolidator.memory_chroma is None:
        print("‚è≠Ô∏è  ChromaDB not available - skipping consolidation")
        print("   (This is expected in test environment)")
    else:
        count = asyncio.run(consolidator._consolidate_to_chroma(successes))
        print(f"üíæ Would consolidate {len(successes)} operations")
        print(f"   Actual consolidated: {count}")
    
    print()
    
    # Test 6: Cleanup Old Operations
    print("Test 6: Cleanup Old Operations (>7 days)")
    
    # Create some very old operations (>7 days)
    for i in range(20, 25):
        timestamp = (datetime.now() - timedelta(days=10)).isoformat()
        
        memory_plugin.save_operation(
            operation_id=f"old_{i}",
            session_id="old_session",
            timestamp=timestamp,
            model_used="llama3.1:8b",
            model_type="local",
            operation_type="llm_call",
            offline_mode=True,
            success=True,
            quality_score=0.80,
            prompt_tokens=100,
            completion_tokens=50,
            total_tokens=150,
            latency_ms=300.0,
            error_message=None,
            raw_metadata="Very old operation"
        )
    
    print(f"‚úÖ Created 5 very old operations (>7 days)")
    
    deleted_count = asyncio.run(consolidator._cleanup_old_operations())
    
    print(f"üóëÔ∏è  Deleted {deleted_count} operations older than 7 days")
    
    if deleted_count == 5:
        print("‚úÖ Cleanup removed correct count")
    else:
        print(f"‚ö†Ô∏è  Expected 5, got {deleted_count}")
    
    print()
    
    # Test 7: DREAM_TRIGGER Event Handler
    print("Test 7: DREAM_TRIGGER Event Handler")
    
    # Subscribe to DREAM_COMPLETE
    dream_complete_received = []
    
    def on_dream_complete(event: Event):
        dream_complete_received.append(event)
        print(f"   üì¢ DREAM_COMPLETE received")
        print(f"      Consolidated: {event.data.get('consolidated_count')}")
        print(f"      Deleted: {event.data.get('deleted_count')}")
    
    event_bus.subscribe(EventType.DREAM_COMPLETE, on_dream_complete)
    
    # Emit DREAM_TRIGGER
    trigger_event = Event(
        EventType.DREAM_TRIGGER,
        data={"trigger_source": "test"}
    )
    
    print("üåô Emitting DREAM_TRIGGER event...")
    
    asyncio.run(consolidator._on_dream_trigger(trigger_event))
    
    if dream_complete_received:
        print("‚úÖ DREAM_COMPLETE event emitted successfully")
    else:
        print("‚ùå DREAM_COMPLETE event not received")
    
    print()
    
    # Test 8: Statistics
    print("Test 8: Check Statistics")
    
    print(f"üìä Consolidator Statistics:")
    print(f"   Last consolidation: {consolidator.last_consolidation}")
    print(f"   Total consolidated: {consolidator.total_consolidated}")
    print(f"   Total deleted: {consolidator.total_deleted}")
    
    if consolidator.last_consolidation and consolidator.total_deleted >= 5:
        print("‚úÖ Statistics tracking working")
    else:
        print("‚ö†Ô∏è  Statistics may be incomplete")
    
    print()
    
    # Summary
    print("üìä TEST SUMMARY:")
    print(f"‚úÖ Infrastructure tests complete")
    print(f"üìà Metrics: {len(old_ops)} old ops, {len(successes)} to consolidate, {deleted_count} deleted")
    print()
    print("üéâ PHASE 3.2 INFRASTRUCTURE COMPLETE!")
    print()
    print("‚ÑπÔ∏è  NOTE: ChromaDB integration requires memory_chroma plugin")
    print("         Current test validates core logic and event flow")


if __name__ == "__main__":
    test_phase_3_2_consolidator()
