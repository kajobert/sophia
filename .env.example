TAVILY_API_KEY=tvly-your-api-key-here

# =============================================================================
# LOCAL LLM CONFIGURATION (Optional)
# =============================================================================
# Run LLMs locally for privacy and cost savings
# Supported runtimes: ollama, lmstudio, llamafile

# Ollama (Recommended - Easy Setup)
# Download: https://ollama.com
# Models: gemma2:2b, llama3.2:3b, phi3:mini
LOCAL_LLM_RUNTIME=ollama
LOCAL_LLM_BASE_URL=http://localhost:11434
LOCAL_LLM_MODEL=gemma2:2b

# LM Studio (GUI Alternative)
# Download: https://lmstudio.ai
# LOCAL_LLM_RUNTIME=lmstudio
# LOCAL_LLM_BASE_URL=http://localhost:1234
# LOCAL_LLM_MODEL=llama-3.2-3b-instruct

# Advanced Settings
LOCAL_LLM_TIMEOUT=120
LOCAL_LLM_MAX_TOKENS=2048
LOCAL_LLM_TEMPERATURE=0.7
