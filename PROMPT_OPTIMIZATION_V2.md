# ğŸ§  SOPHIA Prompt Optimization V2

## ğŸ“‹ Co bylo vylepÅ¡eno

### 1. Dashboard Chat WebSocket komunikace âœ…
**ProblÃ©m**: OdpovÄ›di se nezobrazovaly v Dashboardu
**Fix**: 
- Server nynÃ­ parsuje JSON z Dashboard (`{message: "text"}`)
- OdpovÄ›di posÃ­lÃ¡ jako JSON (`{type: "response", message: "text"}`)
- Frontend sprÃ¡vnÄ› zobrazuje odpovÄ›di

**Soubory**: `plugins/interface_webui.py`

### 2. VylepÅ¡enÃ½ Planner Prompt ğŸš€
**NovÃ½ soubor**: `config/prompts/planner_offline_prompt_v2.txt`

**VylepÅ¡enÃ­**:
- âœ… **JasnÄ›jÅ¡Ã­ formÃ¡tovÃ¡nÃ­** - Markdown sekce s ## headingy
- âœ… **LepÅ¡Ã­ pÅ™Ã­klady** - ÄŒeskÃ© i anglickÃ© dotazy s realistickÃ½mi plÃ¡ny
- âœ… **Planning Strategy** - ExplicitnÃ­ pravidla kdy pouÅ¾Ã­t kterÃ½ tool
- âœ… **VÃ­ce pÅ™Ã­kladÅ¯** - 5 reÃ¡lnÃ½ch use-cases mÃ­sto 3
- âœ… **DÅ¯raz na JSON-only output** - OpakovanÃ© instrukce

**KlÃ­ÄovÃ© zmÄ›ny**:
```
PÅ˜ED:
"CRITICAL INSTRUCTIONS: Output ONLY valid JSON array"

PO:
"## CORE RULES ##
1. Output ONLY a JSON array - NO explanations, NO markdown, NO surrounding text
...
## YOUR JSON PLAN ##" (jasnÃ© oddÄ›lenÃ­)
```

**NovÃ© pÅ™Ã­klady**:
- "Kdo jsi?" â†’ pÅ™Ã­mÃ¡ LLM odpovÄ›Ä (ne zbyteÄnÃ© kroky)
- "JakÃ© jsou tvÃ© schopnosti?" â†’ cognitive_code_reader + system_info + LLM summary
- File operace s ÄeskÃ½mi nÃ¡zvy
- Time queries s ÄeskÃ½m formÃ¡tovÃ¡nÃ­m

### 3. VylepÅ¡enÃ½ SOPHIA DNA Prompt ğŸ¤–
**NovÃ½ soubor**: `config/prompts/sophia_dna_offline_v2.txt`

**VylepÅ¡enÃ­**:
- âœ… **StrukturovanÃ½** - JasnÃ© sekce (Identity, Rules, Principles, Guidelines, Examples)
- âœ… **DO/DON'T checklist** - KonkrÃ©tnÃ­ pÅ™Ã­klady co dÄ›lat a nedÄ›lat
- âœ… **PÅ™Ã­klady odpovÄ›dÃ­** - UkÃ¡zky sprÃ¡vnÃ©ho chovÃ¡nÃ­
- âœ… **KratÅ¡Ã­** - OdstranÄ›no zbyteÄnÃ© filozofickÃ© texty, focus na praktickÃ© pouÅ¾itÃ­
- âœ… **Czech-friendly** - PÅ™Ã­klady v ÄeÅ¡tinÄ›

**KlÃ­ÄovÃ© zmÄ›ny**:
```
PÅ˜ED:
DlouhÃ½ filozofickÃ½ text o vÄ›domÃ­, stoicismu, buddhismu...

PO:
StruÄnÃ¡ pravidla + konkrÃ©tnÃ­ pÅ™Ã­klady:
"User: 'Ahoj, kdo jsi?'
SOPHIA: 'Jsem Sophia, vaÅ¡e umÄ›lÃ¡ mindful inteligence...'"
```

### 4. RobustnÄ›jÅ¡Ã­ JSON Parsing ğŸ’ª
**Soubor**: `plugins/cognitive_planner.py` - funkce `_extract_json_from_text()`

**NovÃ© fallback strategie**:
1. âœ… **Markdown removal** - Stripuje ```json bloky
2. âœ… **Auto-fix zÃ¡vorek** - DoplnÃ­ chybÄ›jÃ­cÃ­ `]` nebo `}`
3. âœ… **Trailing comma removal** - OdstranÃ­ `},]` â†’ `}]`
4. âœ… **Balance check** - SpoÄÃ­tÃ¡ `[` vs `]` a doplnÃ­ rozdÃ­l

**PÅ™Ã­klad auto-fixu**:
```python
# LLM vrÃ¡tÃ­:
[
  {"tool_name": "x", "method_name": "y", "arguments": {}

# Auto-fix doplnÃ­:
[
  {"tool_name": "x", "method_name": "y", "arguments": {}}
]
```

**Logy**:
- `âœ… Auto-fixed 1 missing ]`
- `âœ… Auto-fixed 2 missing }}`

## ğŸ”„ Jak aktivovat vylepÅ¡enÃ­

### Metoda 1: ManuÃ¡lnÃ­ aktivace (doporuÄeno pro test)
```bash
cd /mnt/c/SOPHIA/sophia

# ZÃ¡loha souÄasnÃ½ch promptÅ¯
cp config/prompts/planner_offline_prompt.txt config/prompts/planner_offline_prompt_old.txt
cp config/prompts/sophia_dna_offline.txt config/prompts/sophia_dna_offline_old.txt

# Aktivace V2
cp config/prompts/planner_offline_prompt_v2.txt config/prompts/planner_offline_prompt.txt
cp config/prompts/sophia_dna_offline_v2.txt config/prompts/sophia_dna_offline.txt

# Restart SOPHIA
export PATH="/mnt/c/SOPHIA/sophia/bin:$PATH"
sophia-stop
sophia-start
```

### Metoda 2: TestovÃ¡nÃ­ obou verzÃ­
```bash
# Test s V1 (souÄasnÃ¡ verze)
echo "Test query" | .venv/bin/python run.py --single "JakÃ© jsou tvÃ© schopnosti?"

# Switni na V2
cp config/prompts/planner_offline_prompt_v2.txt config/prompts/planner_offline_prompt.txt

# Test s V2
echo "Test query" | .venv/bin/python run.py --single "JakÃ© jsou tvÃ© schopnosti?"

# Porovnej vÃ½sledky
```

### Metoda 3: PokroÄilÃ¡ - Self-tuning overnight
V budoucnu mÅ¯Å¾eÅ¡ pouÅ¾Ã­t `cognitive_self_tuning` plugin aby SOPHIA sama testovala obÄ› verze a vybrala lepÅ¡Ã­:

```python
# V cognitive_self_tuning.py:
test_prompts = [
    "config/prompts/planner_offline_prompt.txt",  # V1
    "config/prompts/planner_offline_prompt_v2.txt"  # V2
]

# Plugin pÅ™es noc testuje obÄ› verze na benchmark sadÄ›
# VyhodnotÃ­:
# - Success rate (kolik plÃ¡nÅ¯ je validnÃ­ JSON)
# - Plan quality (kolik krokÅ¯, sprÃ¡vnost tool selection)
# - Response quality (pomocÃ­ Claude/GPT jako judge)

# Automaticky aktivuje lepÅ¡Ã­ verzi
```

## ğŸ“Š OÄekÃ¡vanÃ© vÃ½sledky

### PÅ™ed (V1):
```
User: "JakÃ© jsou tvÃ© schopnosti?"
Plan: [
  {"tool_name": "tool_local_llm", "method_name": "execute_local_llm", "arguments": {"context": "Tell about capabilities"}}
]
âŒ ProblÃ©m: ZbyteÄnÃ© volÃ¡nÃ­ LLM bez system tools
```

### Po (V2):
```
User: "JakÃ© jsou tvÃ© schopnosti?"
Plan: [
  {"tool_name": "cognitive_code_reader", "method_name": "list_plugins", "arguments": {}},
  {"tool_name": "tool_system_info", "method_name": "get_system_info", "arguments": {}},
  {"tool_name": "tool_local_llm", "method_name": "execute_local_llm", "arguments": {"context": "Based on plugins: ${step_1.plugins} and system: ${step_2.info}, tell capabilities in Czech"}}
]
âœ… LepÅ¡Ã­: PouÅ¾Ã­vÃ¡ system tools, pak formÃ¡tuje LLM
```

### JSON Parsing:
```
PÅ˜ED:
LLM output: [{"tool": "x"
Parser: âŒ JSON decode error
Result: Empty plan []

PO:
LLM output: [{"tool": "x"
Parser: âœ… Auto-fixed 1 missing }]
Result: Valid plan [{"tool": "x"}]
```

## ğŸ”¬ Benchmark test

MÅ¯Å¾eÅ¡ spustit test na sadÄ› dotazÅ¯:
```bash
# VytvoÅ™ test soubor
cat > test_prompts.txt << 'EOF'
Ahoj, kdo jsi?
JakÃ© jsou tvÃ© schopnosti?
Kolik je hodin?
Co je v souboru config/settings.yaml?
VytvoÅ™ soubor test.txt s obsahem "Hello"
EOF

# Test V1
while read query; do
    echo "=== $query ==="
    .venv/bin/python run.py --single "$query" 2>&1 | grep -A 5 "Plan:\|Result:"
done < test_prompts.txt > results_v1.txt

# Aktivuj V2
cp config/prompts/planner_offline_prompt_v2.txt config/prompts/planner_offline_prompt.txt

# Test V2
while read query; do
    echo "=== $query ==="
    .venv/bin/python run.py --single "$query" 2>&1 | grep -A 5 "Plan:\|Result:"
done < test_prompts.txt > results_v2.txt

# PorovnÃ¡nÃ­
diff -u results_v1.txt results_v2.txt
```

## ğŸŒ™ Overnight Self-Improvement

Pokud chceÅ¡ aby se SOPHIA sama zdokonalovala pÅ™es noc:

### 1. Aktivuj Jules integration
V `.env`:
```bash
JULES_API_KEY=your_gemini_api_key
JULES_ENDPOINT=https://your-jules-api.com
```

### 2. Aktivuj autonomous mode
```bash
# SpusÅ¥ v background reÅ¾imu s benchmarking
nohup .venv/bin/python run.py --autonomous --benchmark-interval 3600 > logs/overnight.log 2>&1 &
```

### 3. Co se stane:
- KaÅ¾dou hodinu (`--benchmark-interval 3600`) spustÃ­ benchmark sadu
- `cognitive_reflection` analyzuje failures
- `cognitive_self_tuning` testuje prompt varianty
- Pokud najde lepÅ¡Ã­ prompt (>10% improvement), aktivuje ho
- Jules (Gemini 2.0 Flash) pomÃ¡hÃ¡ s kvalitnÃ­mi analÃ½zami
- RÃ¡no: `logs/overnight.log` obsahuje report zmÄ›n

### 4. RÃ¡no zkontroluj:
```bash
grep "âœ… Activated better prompt" logs/overnight.log
grep "ğŸ“Š Improvement:" logs/overnight.log
tail -100 logs/overnight.log
```

## ğŸ¯ DalÅ¡Ã­ kroky

1. **Test V2 promptÅ¯** - ManuÃ¡lnÄ› aktivuj a vyzkouÅ¡ej Dashboard Chat
2. **Benchmark** - Porovnej V1 vs V2 na testovacÃ­ sadÄ›
3. **Fine-tuning** - Pokud V2 funguje lÃ©pe, stane se default
4. **Overnight mode** - Aktivuj autonomous zdokonalovÃ¡nÃ­
5. **Model upgrade** - AÅ¾ pÅ™idÃ¡Å¡ OpenRouter, zkus GPT-4 jako planner pro sloÅ¾itÃ© dotazy

## ğŸ“ PoznÃ¡mky

- **Dashboard Chat fix je aktivnÃ­** - StaÄÃ­ restart SOPHIA
- **V2 prompty jsou ready** - ÄŒekajÃ­ na aktivaci
- **JSON parsing fix je aktivnÃ­** - Auto-opravy fungujÃ­
- **Backward compatible** - V1 prompty zÃ¡lohovanÃ©, mÅ¯Å¾eÅ¡ kdykoliv vrÃ¡tit

---

**Status**: âœ… Ready for testing
**Autor**: GitHub Copilot
**Datum**: 7.11.2025
